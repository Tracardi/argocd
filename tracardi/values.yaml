# Infrastructure

elastic:
  # Identifier for Elasticsearch service instance
  name: es1
  # Host address for Elasticsearch
  host: elastic-std-svc.elastic-standalone.svc.cluster.local
  # Protocol for connecting to Elasticsearch (http/https)
  schema: http
  # Enable or disable authentication for Elasticsearch
  authenticate: false
  # Port number for Elasticsearch service
  port: 9200
  # Whether to verify SSL certificates (yes/no)
  verifyCerts: "no"
  index:
    # Number of primary shards for Elasticsearch index
    shards: 3
    # Number of replica shards for Elasticsearch index
    replicas: 1

redis:
  # Identifier for Redis service instance
  name: rd1
  # Host address for Redis
  host: redis-std-svc.redis-standalone.svc.cluster.local
  # Protocol for connecting to Redis
  schema: "redis://"
  # Enable or disable authentication for Redis
  authenticate: false
  # Port number for Redis service
  port: 6379
  # Redis database number to use
  db: "0"
  # Enable redis service
  enabled: true

pulsar:
  # Identifier for Pulsar service instance
  name: ps1
  # Host address for Pulsar
  host: pulsar-std-svc.pulsar-standalone.svc.cluster.local
  # Pulsar API endpoint
  api: "http://pulsar-std-svc.pulsar-standalone.svc.cluster.local:8080"
  # Protocol for connecting to Pulsar
  schema: "pulsar://"
  # Enable or disable authentication for Pulsar
  authenticate: false
  # Port number for Pulsar service
  port: 6650
  cluster_name: pulsar
  # Enable pulsar service
  enabled: true

kafka:
  # Identifier for Kafka service instance
  name: kf1
  # Host address for Kafka
  host: kafka-std-svc.kafka.svc.cluster.local
  # Port number for Kafka service
  port: 9092
  metadata_max_age_ms: 300000
  request_timeout_ms: 40000
  max_batch_size: 16384
  max_request_size: 1048576
  # Enable or disable authentication for Pulsar
  authenticate: true
  # Enable kafka service
  enabled: true

mysql:
  # Identifier for MySQL service instance
  name: ms1
  # Host address for MySQL
  host: percona-db-pxc-db-haproxy.percona.svc.cluster.local
  # Protocol for connecting to MySQL
  schema: "mysql+aiomysql://"
  # Database name for MySQL
  database: "tracardi"
  # Port number for MySQL service
  port: 3306
  pool:
    # Number of connections in the connection pool
    size: 5
    # Number of additional connections beyond the pool size
    maxOverflow: 2
    # Timeout for acquiring a connection from the pool
    timeout: 3
    # Time after which a connection in the pool is recycled
    recycle: 1800

# Not used
#starrocks:
#  host: "localhost"
#  username: "root"
#  password: "root"
#  schema: "mysql+aiomysql://"
#  schemaSync: "mysql+pymysql://"
#  port: 9030
#  database: "tracardi"
#  echo: "no"


# Tenant Management Service (TMS) API configuration
tmsApi:
  # Host address for TMS API service, It is server by pod be-fa-tms
  host: be-tms-svc
  # Database name for TMS API
  database: "tms"

# Not used. Experimental
#telemetry:
#  disabled: true
#  name: "tracardi"
#  log_level: "info"
#  export:
#    endpoint: "" # e.g.http://localhost:4317  # OTEL_EXPORTER_OTLP_ENDPOINT
#    headers: ""  # Use when needed
#    metrics: "" # Use when needed
#    logs: "" # Use when needed
#    attributes: "" # Use when needed
#    time_out: 30000
#    delay: 5000
#    batch_size: 512


# Cluster-wide Configuration: General settings for Tracardi system
config:
  queue:
    adapter: "pulsar"
  # Enable or disable multi-tenancy
  multiTenant:
    multi: "no"
  # Primary ID prefix; should be set only once and never changed
  primaryId: "emm-"
  # Enable or disable demo mode
  demo: "no"
  apm:
    identificationEventProperty: ""
    tipType: ""
    eventType: ""
  # Experimental Feature Flag
  eff:
    enableLateProfileBinding: "no"
  # Enable features for various aspects of the Tracardi system
  features:
    enableEventDestinations: "yes"
    enableProfileDestinations: "yes"
    enableAudiences: "yes"
    enableWorkflow: "yes"
    enableEventValidation: "yes"
    enableEventReshaping: "yes"
    enableEventMapping: "yes"
    enableEventToProfileMapping: "yes"
    enableDataCompliance: "yes"
    enableEventSourceCheck: "yes"
    enableIdentificationPoints: "yes"
  systemEvents:
    # Enable or disable system events
    enabled: "yes"
    # Set what profile properties should be monitored for change
    monitorPropertyChange: null
    # Enable visit-ended event handling
    collectVisitEnded: "no"
  # Cache expiration settings in seconds
  cache:
    # Time in seconds to keep profile data in cache
    keepProfileInCacheFor: 3600
    # Time in seconds to keep session data in cache
    keepSessionInCacheFor: 1800

  visit:
    # Time in seconds after inactivity to close a visit
    close: 1200

  preConfiguration:
    resources: "{}"
    eventSources: "{}"
    destinations: "{}"
    tenantAliases: "{}"

# Definition of defined secrets.

secrets:
  dockerHub: "tracardi-dockerhub"

  installation:
    token: "tracardi"  # Random value
    valueFrom:
      token:
        name: ""
        key: ""

  license:
    licenseKey: ""
    valueFrom:
      licenseKey:
        name: ""
        key: ""

  tms:
    secretKey: ""  # Random value
    apiKey: ""    # Random value
    valueFrom:
      secretKey:
        name: ""
        key: ""
      apiKey:
        name: ""
        key: ""

  redis:
    password: ""
    valueFrom:
      password:
        name: ""
        key: ""

  elastic:
    username: "elastic"
    password: ""
    valueFrom:
      username:
        name: ""
        key: ""
      password:
        name: ""
        key: ""

  pulsar:
    token: ""
    valueFrom:
      token:
        name: ""
        key: ""

  kafka:
    security_protocol: "PLAINTEXT"
    sasl:
      mechanism: "PLAIN"
      username: null
      password: null
      valueFrom:
        username:
          name: ""
          key: ""
        password:
          name: ""
          key: ""
    # Kafka certificates
    cafile: |
      -----BEGIN CERTIFICATE-----
      YOUR_CA_CERTIFICATE_CONTENT
      -----END CERTIFICATE-----
    certfile: |
      -----BEGIN CERTIFICATE-----
      YOUR_CERTIFICATE_CONTENT
      -----END CERTIFICATE-----
    key_file: |
      -----BEGIN PRIVATE KEY-----
      YOUR_KEY_CONTENT
      -----END PRIVATE KEY-----

  mysql:
    username: ""
    password: ""
    valueFrom:
      username:
        name: ""
        key: ""
      password:
        name: ""
        key: ""

  maxmind:
    licenseKey: ""
    accountId: ""
    valueFrom:
      licenseKey:
        name: ""
        key: ""
      accountId:
        name: ""
        key: ""

  mergingToken: "1180015e-38d0-4eb7-8017-40e6a7937659"  # Random value

api:
  image:
    repository: tracardi/com-tracardi-api
    pullPolicy: IfNotPresent
    tag: 1.2.x  # Tag should be the same for gui and backend
  private:
    enabled: true
    replicas: 1
    config:
      saveLogs: "yes"
      loggingLevel: "INFO"
      apiDocs: "yes"
      enableWorkflow: "yes"
      enableEventDestinations: "yes"
      enableProfileDestinations: "yes"
      enableIdentification: "yes"
      eventPartitioning: "month"
      profilePartitioning: "quarter"
      sessionPartitioning: "quarter"
    service:
      port: 8686
      loadBalancer: false
    ingress:
      enabled: false
      host: "*.private.your-domain.com"
      path: /
      limit:
        enabled: false
        connections: "20" # Max concurrent connections
        rps: "10"         # Max requests per second
        burstMultiplier: "2" # Burst requests allowed
        zone: "private-api"
    resources:
      limits:
        memory: 1000Mi  # Private need more memory because it can run workflows
        cpu: 500m
      requests:
        memory: 100Mi
        cpu: 100m

# Example of nodeAffinity
#    nodeAffinity:
#      required:
#        - key: node-type
#          operator: In
#          values:
#            - compute
#      preferred:
#        - weight: 100
#          key: zone
#          operator: In
#          values:
#            - us-east-1a
#        - weight: 50
#          key: instance-type
#          operator: In
#          values:
#            - c5.xlarge

  public:
    enabled: true
    spread:
      rules:
        topologySpreadConstraints:
          - maxSkew: 1
            topologyKey: kubernetes.io/hostname
            whenUnsatisfiable: ScheduleAnyway
            labelSelector:
              matchLabels:
                app.kubernetes.io/component: be-fa-public
    replicas: 1
    config:
      saveLogs: "yes"
      loggingLevel: "INFO"
      apiDocs: "no"
      eventPartitioning: "month"
      profilePartitioning: "quarter"
      sessionPartitioning: "quarter"
      entityPartitioning: "quarter"

    storage:
      failOver:
        enabled: false
        size: 1Gi
    service:
      port: 8585
      loadBalancer: false
    ingress:
      enabled: false
      host: "*.public.your-domain.com"
      path: /
      limit:
        enabled: false
        connections: "20" # Max concurrent connections
        rps: "10"         # Max requests per second
        burstMultiplier: "2" # Burst requests allowed
        zone: "public-api"
    resources:
      limits:
        memory: 300Mi
        cpu: 500m
      requests:
        memory: 100Mi
        cpu: 100m

# Example of nodeAffinity
#    nodeAffinity:
#      required:
#        - key: node-type
#          operator: In
#          values:
#            - compute
#      preferred:
#        - weight: 100
#          key: zone
#          operator: In
#          values:
#            - us-east-1a
#        - weight: 50
#          key: instance-type
#          operator: In
#          values:
#            - c5.xlarge

gui:
  image:
    repository: tracardi/tracardi-com-gui
    pullPolicy: IfNotPresent
    tag: 1.2.x  # Tag should be the same for gui and backend
  console:
    enabled: true
    replicas: 1
    service:
        port: 8787
        loadBalancer: false
    ingress:
      enabled: false
      host: gui.your-domain.com
      path: /
    config:
      mode: "with-deployment"
      allowUpdatesOnProduction: "no"
# Example of nodeAffinity
#  nodeAffinity:
#    required:
#      - key: node-type
#        operator: In
#        values:
#          - compute
#    preferred:
#      - weight: 100
#        key: zone
#        operator: In
#        values:
#          - us-east-1a
#      - weight: 50
#        key: instance-type
#        operator: In
#        values:
#          - c5.xlarge

tms:
  image:
    repository: tracardi/tms
    pullPolicy: IfNotPresent
    tag: 1.2.x  # Tag should be the same for gui and backend
  docker:
    enabled: true
    replicas: 1
    config:
      loggingLevel: "INFO"
    service:
      port: 8383
      name: be-tms-svc  # The name of tms service
      loadBalancer: false

# Example of nodeAffinity
#    nodeAffinity:
#      required:
#        - key: node-type
#          operator: In
#          values:
#            - compute
#      preferred:
#        - weight: 100
#          key: zone
#          operator: In
#          values:
#            - us-east-1a
#        - weight: 50
#          key: instance-type
#          operator: In
#          values:
#            - c5.xlarge
tmsGui:
  image:
    repository: tracardi/tms-gui
    pullPolicy: IfNotPresent
    tag: 1.2.x  # Tag should be the same for gui and backend
  docker:
    enabled: true
    replicas: 1
    service:
      port: 8282
      loadBalancer: false




# Example of nodeAffinity
#  nodeAffinity:
#    required:
#      - key: node-type
#        operator: In
#        values:
#          - compute
#    preferred:
#      - weight: 100
#        key: zone
#        operator: In
#        values:
#          - us-east-1a
#      - weight: 50
#        key: instance-type
#        operator: In
#        values:
#          - c5.xlarge

worker:
  background:

    enabled: true

    image:
      repository: tracardi/background-worker
      tag: 1.2.x
      pullPolicy: IfNotPresent

    replicas: 1

    spread:
      rules:
        topologySpreadConstraints:
          - maxSkew: 1
            topologyKey: kubernetes.io/hostname
            whenUnsatisfiable: ScheduleAnyway
            labelSelector:
              matchLabels:
                app.kubernetes.io/component: wk-pl-background
    config:
      loggingLevel: "INFO"
      bulker:
        # Data Bulker
        #
        # The Data Bulker Configuration are setting for message bulker that is responsible for collecting messages and
        # managing them for background storage operations.
        #
        # It operates by enforcing two main constraints: a size limit, which is the maximum number of messages the queue can
        # hold, and a time limit, which dictates how long messages can remain in the queue. If either of these limits is
        # exceeded, the queued data is flushed to storage.
        #
        # Additionally, if no new data arrives within a specified period of inactivity, a timeout is triggered that
        # automatically flushes any remaining data in the queue that has not yet been processed.
        bufferInactivityTimeOut: 10000 # If there is no data in then flash remaining buffer to storage in X milliseconds

    resources:
      limits:
        memory: 500Mi # 400Mi max for worker that saves data only, not collector
        cpu: 1000m  # 700m max for worker that saves data only, not collector
      requests:
        memory: 300Mi
        cpu: 300m

# Example of nodeAffinity
#    nodeAffinity:
#      required:
#        - key: node-type
#          operator: In
#          values:
#            - compute
#      preferred:
#        - weight: 100
#          key: zone
#          operator: In
#          values:
#            - us-east-1a
#        - weight: 50
#          key: instance-type
#          operator: In
#          values:
#            - c5.xlarge

  collector:

    enabled: False

    image:
      repository: tracardi/background-worker
      tag: 1.2.x
      pullPolicy: IfNotPresent

    replicas: 1

    spread:
      rules:
        topologySpreadConstraints:
          - maxSkew: 1
            topologyKey: kubernetes.io/hostname
            whenUnsatisfiable: ScheduleAnyway
            labelSelector:
              matchLabels:
                app.kubernetes.io/component: wk-pl-background

    resources:
      limits:
        memory: 500Mi # 400Mi max for worker that saves data only, not collector
        cpu: 1000m  # 700m max for worker that saves data only, not collector
      requests:
        memory: 300Mi
        cpu: 300m

    config:
      loggingLevel: "INFO"
      bulker:
        # Data Bulker
        #
        # The Data Bulker Configuration are setting for message bulker that is responsible for collecting messages and
        # managing them for background storage operations.
        #
        # It operates by enforcing two main constraints: a size limit, which is the maximum number of messages the queue can
        # hold, and a time limit, which dictates how long messages can remain in the queue. If either of these limits is
        # exceeded, the queued data is flushed to storage.
        #
        # Additionally, if no new data arrives within a specified period of inactivity, a timeout is triggered that
        # automatically flushes any remaining data in the queue that has not yet been processed.
        bufferInactivityTimeOut: 10000 # If there is no data in then flash remaining buffer to storage in X milliseconds

  workflow:

    enabled: False

    image:
      repository: tracardi/background-worker
      tag: 1.2.x
      pullPolicy: IfNotPresent

    replicas: 1

    spread:
      rules:
        topologySpreadConstraints:
          - maxSkew: 1
            topologyKey: kubernetes.io/hostname
            whenUnsatisfiable: ScheduleAnyway
            labelSelector:
              matchLabels:
                app.kubernetes.io/component: wk-pl-workflow

    resources:
      limits:
        memory: 500Mi # 400Mi max for worker that saves data only, not collector
        cpu: 800m  # 700m max for worker that saves data only, not collector
      requests:
        memory: 200Mi
        cpu: 300m

    config:
      loggingLevel: "INFO"
      bulker:
        # Data Bulker
        #
        # The Data Bulker Configuration are setting for message bulker that is responsible for collecting messages and
        # managing them for background storage operations.
        #
        # It operates by enforcing two main constraints: a size limit, which is the maximum number of messages the queue can
        # hold, and a time limit, which dictates how long messages can remain in the queue. If either of these limits is
        # exceeded, the queued data is flushed to storage.
        #
        # Additionally, if no new data arrives within a specified period of inactivity, a timeout is triggered that
        # automatically flushes any remaining data in the queue that has not yet been processed.
        bufferInactivityTimeOut: 10000 # If there is no data in then flash remaining buffer to storage in X milliseconds

# Example of nodeAffinity
#    nodeAffinity:
#      required:
#        - key: node-type
#          operator: In
#          values:
#            - compute
#      preferred:
#        - weight: 100
#          key: zone
#          operator: In
#          values:
#            - us-east-1a
#        - weight: 50
#          key: instance-type
#          operator: In
#          values:
#            - c5.xlarge

  apm:
    image:
      repository: tracardi/apm
      tag: 1.2.x
      pullPolicy: IfNotPresent
    profile:
      enabled: true
      replicas: 1
      config:
        loggingLevel: "INFO"

# Example of nodeAffinity
#    nodeAffinity:
#      required:
#        - key: node-type
#          operator: In
#          values:
#            - compute
#      preferred:
#        - weight: 100
#          key: zone
#          operator: In
#          values:
#            - us-east-1a
#        - weight: 50
#          key: instance-type
#          operator: In
#          values:
#            - c5.xlarge

  upgrade:
    image:
      repository: tracardi/update-worker
      tag: 1.2.x
      pullPolicy: IfNotPresent
    docker:
      enabled: true
      replicas: 1
      config:
        saveLogs: "no"
        loggingLevel: "INFO"
      resources:
        limits:
          memory: 500Mi
          cpu: 500m

# Bridges. Services responsible for collection data from different channels. They bridge the defined transportation protocol to tracardi event source.

bridge:
  queue:
    image:
      repository: tracardi/com-bridge-queue
      tag: 1.2.x
      pullPolicy: IfNotPresent
    docker:
      enabled: false
      replicas: 1
      config:
        loggingLevel: "INFO"

